<h1 align="center" style="border-bottom: none">
    <b>
        <a href=""> Healthcare Website </a><br>
</h1>

# [Website link](http://www.google.com)  [`Demo video link `](http://www.google.com)
Automatic Mouse Hand Control integrates hardware (mouse) with software (gesture recognition, simulation algorithms) to enable users to manipulate a virtual hand through mouse movements, enhancing accessibility and interaction for those with limited mobility.
## Team Details
Team number : VH096

| Name    | Email           |
|---------|-----------------|
| K CHENCHU NAGA SAI | 99210041394@klu.ac.in |
| CH AKASH | 9921004131@klu.ac.in |
| B MANOJ KUMAR REDDY | 99210041764@klu.ac.in |
| B TEJASIWINI | 9921004841@klu.ac.in |

## Problem statement 
Addressing the needs of individuals with limited hand mobility, the project aims to develop a robust system for automatic mouse control using hand gestures. Challenges include precise gesture recognition, real-time hand movement simulation, and intuitive user interface design to enhance accessibility and usability for users with diverse mobility needs.
## About the project
The project aims to create an automatic mouse control system utilizing hand gestures, catering to individuals with limited hand mobility. It focuses on precise gesture recognition, real-time hand movement simulation, and intuitive user interface design for enhanced accessibility and usability.

       <img src="https://www.tecnoaccesible.net/en/virtual-mouse" alt="Image 1" style="width: 30%; margin: 5px;">
       <img src="https://images.app.goo.gl/pwFmpPsTuKUz8vReA" alt="Image 2" style="width: 30%; margin: 5px;">

## The Problem It Solves


## Technical implemntaion 
Technical implementation for automatic mouse using hand control entails creating software to interpret mouse movements, recognize gestures, and simulate corresponding hand movements. This is done using algorithms for gesture recognition, hand movement simulation, and real-time feedback, as well as customization options and extensive testing for accuracy and usability.
![flowchart](https://www.google.com/imgres?imgurl=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F338701325%2Ffigure%2Ffig1%2FAS%3A849962380324864%401579658231039%2FFlowchart-of-virtual-mouse-system-Flowchart-of-virtual-mouse-system.png&tbnid=0dYpSO9LhM-SGM&vet=1&imgrefurl=https%3A%2F%2Fwww.researchgate.net%2Ffigure%2FFlowchart-of-virtual-mouse-system-Flowchart-of-virtual-mouse-system_fig1_338701325&docid=3FP8iu2KHg3SXM&w=850&h=345&itg=1&hl=en-GB&source=sh%2Fx%2Fim%2Fm1%2F4&kgs=6d0a1a47165786ae&shem=trie)
## Techstacks used 
tkinter,python
## How to run locally 
to run my code follow the steps:

download my repository as a zip folder
extract that folder and run the mlproject.py file that the the main file which uses hand control code and image in it
# What's next ?
Future plans for automatic mouse using hand control include improving gesture recognition, integrating with VR/AR, enabling mobile and wearable control, enhancing accessibility, adding collaboration features, refining user interface, ensuring cross-platform compatibility, and investing in ongoing research and development.
## Declaration
We confirm that the project showcased here was either developed entirely during the hackathon or underwent significant updates within the hackathon timeframe. We understand that if any plagiarism from online sources is detected, our project will be disqualified, and our participation in the hackathon will be revoked.# Automatic-Mouse-Using-Hand-Control
